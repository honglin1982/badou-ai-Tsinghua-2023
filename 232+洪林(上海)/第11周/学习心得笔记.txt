【11.1】Cifar.ev4a
图像增强：   Cifar10_data.py
#首先将预处理好的图片进行剪切，使用tf.random_crop()函数
#将剪切好的图片进行左右翻转，使用tf.image.random_flip_left_right()函数
#将左右翻转好的图片进行随机亮度调整，使用tf.image.random_brightness()函数
#将亮度调整好的图片进行随机对比度调整，使用tf.image.random_contrast()函数
#进行标准化图片操作，tf.image.per_image_standardization()函数是对每一个像素减去平均值并除以像素方差

===========================================================================
【11.2】Alexnet.ev4a
我们之后的重点，放在常见的神经网络以及它的结构。
各种不同的网络结构上，因为这些不同的网络结构，它的推理和训练的过程是一样的。
我们重点要看，各种不同的网络结构，带来的不同的效果。来增加我们的经验和方法的积累。
(00:00:50)

BatchNormalization层：归一化
===========================================================================
【11.3】VGG.ev4a
特征抽取和选择：各式各样的 卷积 组成，来进行特征提取。
分类器设计：全连接部分，连接softmax进行分类。

检测：例如我知道这个图像是关于人脸的，那么这个人脸在哪里，能不能把它框出来。

卷积核比较小，可以得到更细节的一些特征(00:18:20)
而层数增多，也可以得到更多的特征。

卷积核的层数可以增加，但不能无脑的无限增加，否则会导致过拟合(00:18:40)

vgg，也不是简简单单的做深，就达成了。他为什么是16层、19层，而不是20层、100层？他是有讲究的。
在这种结构下，不至于产生过拟合，同时，特征提取的效果又比较好(00:19:00)


VGG16的结构：
1、一张原始图片被resize到(224,224,3)。
(224,224,3)，是很多 图像分类的模型，要求的输入，这是大家公认的、相对比较合适的大小.       (00:20:33)

拍扁操作，在某些硬件上，还是比较耗时的。
所有层 没有全连接，只有卷积类层的网络，叫 全卷积神经网络，FCN(Fully Convolutional Network)。 (00:28:36)
===========================================================================
【11.4】Resnet.ev4a
Resnetf非常经典，在加深网络的同时，尽可能的保留了网络的信息。  (00:18:32)

Resnet，在串行的基础上，增加了残差。(00:19:39)
他的层深，可以比vgg还要深，但是他的效果去比vgg好，原因就是他有两种block的存在(Conv Block和Identity Block)。

他利用了残差结构，使得他即使深度增加，也不会有一些过拟合，或者信息丢失的问题。(00:20:00)
当然，不能无限增加。这也是实验的结果。

为什么Resnet地位非常高，他是一个比较万金油的网络。(00:20:29)

【Conv Block】
左边：信息丢失更多，但是提取的特征也会越细(00:54:28)
右边：提取了一个比较高层的局部信息，然后信息丢失相对比较少。

因为Resnet50比较万金油，很多情况下，你直接拿来用就可以。这也是为什么他很经典，用的人多，商业落地产品中用的多的原因。(00:55:48)
简单易用
===========================================================================



===========================================================================

