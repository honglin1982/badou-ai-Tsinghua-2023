【10.1】深度学习框架.ev4a

我们课上，TensorFlow用的是1.x，而不是2.x版本(00:32:12)
===========================================================================
【10.2】TensorFlow.ev4a

拓展-Tensorflow--可视化工具TensorBoard
需要自己运行  (00:50:00)

查 TensorFlow 官方手册

查device信息：cnmon (跟我们的课没什么关系)
===========================================================================
【10.3】pytorch.ev4a
已看完
===========================================================================
【10.4】CNN.ev4a
卷积神经网络带给我们新的东西，是特征提取部分；而分类部分，还是我们之前学的传统神经网络。(00:15:25)
强强联合，得到了我们现在最火爆的神经网络。

池化，做了一个降维的事。 (00:20:40)
虽然压缩了数据，但是尽可能减少了数据丢失，因为拿到的都是比较有特点的数据。(00:23:28)

卷积后会有各种各样的特征，每个特征一个通道   (00:24:36)

卷积和全连接没有本质区别：   (00:28:35)
全连接：输入的每一个点，和输出的每一个点，都连接。
当卷积核大到和图像一样大尺寸的时候，和全连接就完全一样了。
所以，可以认为，全连接是卷积的一种特殊情况。

FC不能接受一维以外的，只能接受一维。需要有一个【拍扁】的过程  (00:36:34)
把卷积结果【拍扁】，才能给到FC
全卷积神经网络，没有FC，就不需要【拍扁】的过程

【解答】
通过卷积增加厚度，不是通过池化增加厚度。        (00:48:40)
减少长宽是通过池化。

输出的通道数，等于卷积核的数量。        (00：50：00)
每一个卷积核代表一个特征。
卷积核的通道数，等于输入的通道数。

输入input：
(ci, hi, wi)
权重w：
(n, c ,kh, kw) = (co, ci, kh, kw)           k是kernel的意思，卷积核
输出output：
(co, ho ,wo)
output的channel，由权重的个数决定。
===========================================================================



===========================================================================

